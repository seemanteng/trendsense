TrendSense ğŸ“°

Real-time Singapore news and social media trend analyzer with sentiment analysis and interactive visualization


ğŸš€ Features

ğŸŒ Multi-Source Data Collection

Hacker News trending tech stories
NewsAPI for Singapore-focused articles
Reddit posts from Singapore communities
Configurable RSS feed integration


ğŸ§  Advanced NLP Analysis

Real-time sentiment analysis (TextBlob + VADER)
Topic clustering and trend detection
Singapore-specific content filtering
Tech industry focus with smart keyword matching


ğŸ“Š Interactive Dashboard

Live data visualization with Plotly
Sentiment trends over time
Source distribution analytics
Story popularity metrics


ğŸ”§ Production Ready

SQLAlchemy database integration
Automated scheduling and data collection
Comprehensive logging and error handling
Modular, scalable architecture

ğŸ› ï¸ Tech Stack

Backend: Python 3.8+, SQLAlchemy, SQLite
Frontend: Streamlit, Plotly, HTML/CSS
APIs: NewsAPI, Reddit API (PRAW), Hacker News API
NLP: TextBlob, VADER Sentiment, spaCy
Data Processing: Pandas, NumPy
Deployment: Docker-ready, environment-based configuration

# Quick Start
Prerequisites

Python 3.8 or higher
Git
Internet connection for API access

1. Clone and Setup
bash# Clone the repository
git clone https://github.com/seemanteng/trendsense.git
cd trendsense

# Create virtual environment (OUTSIDE project directory)
cd ..
python -m venv trendsense_env
source trendsense_env/bin/activate  # On Windows: trendsense_env\Scripts\activate

# Install dependencies
cd trendsense
pip install -r requirements.txt

# Download spaCy language model
python -m spacy download en_core_web_sm
2. Configuration
bash# Copy environment template
cp .env.example .env

# Edit .env with your API keys (see API Setup section below)
nano .env  # or use your preferred editor
3. Initialize Database
bashpython scripts/setup_db.py
4. Run the Application
bash# Start data collection (in one terminal)
python scripts/run_scraper.py

# Launch dashboard (in another terminal)
streamlit run dashboard/app.py
Visit http://localhost:8501 to access the dashboard.
API Setup
Required APIs
1. NewsAPI (Required)

Visit newsapi.org
Sign up for a free account
Copy your API key to .env file:

envNEWS_API_KEY=your_newsapi_key_here
2. Reddit API (Optional but Recommended)

Go to reddit.com/prefs/apps
Click "Create App"
Choose "script" type
Fill in your details:

Name: TrendSense
Description: News trend analyzer
Redirect URI: http://localhost:8080


Add credentials to .env:

envREDDIT_CLIENT_ID=your_client_id
REDDIT_CLIENT_SECRET=your_client_secret
REDDIT_USER_AGENT=TrendSense/1.0
3. Hacker News (No Setup Required)

Uses public API - no authentication needed!

# Project Structure
<pre>
trendsense/
â”œâ”€â”€ config/                 # Configuration files
â”‚   â”œâ”€â”€ settings.py         # Main app configuration
â”‚   â””â”€â”€ database.py         # Database setup
â”œâ”€â”€ src/                    # Core application code
â”‚   â”œâ”€â”€ scrapers/           # Data collection modules
â”‚   â”‚   â”œâ”€â”€ news_scraper.py     # NewsAPI + RSS integration
â”‚   â”‚   â”œâ”€â”€ reddit_scraper.py   # Reddit data collection
â”‚   â”‚   â””â”€â”€ hackernews_scraper.py # Hacker News integration
â”‚   â”œâ”€â”€ nlp/                # Natural language processing
â”‚   â”‚   â”œâ”€â”€ sentiment_analysis.py # Sentiment analysis pipeline
â”‚   â”‚   â””â”€â”€ topic_clustering.py   # Topic detection
â”‚   â”œâ”€â”€ data/               # Database models and management
â”‚   â”‚   â”œâ”€â”€ models.py           # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ database_manager.py # Database operations
â”‚   â””â”€â”€ utils/              # Utility functions
â”‚       â”œâ”€â”€ logger.py           # Logging configuration
â”‚       â””â”€â”€ helpers.py          # Helper functions
â”œâ”€â”€ dashboard/              # Streamlit web interface
â”‚   â”œâ”€â”€ app.py              # Main dashboard application
â”‚   â””â”€â”€ components/         # Dashboard components
â”œâ”€â”€ scripts/                # Automation and setup scripts
â”‚   â”œâ”€â”€ setup_db.py         # Database initialization
â”‚   â”œâ”€â”€ run_scraper.py      # Main data collection script
â”‚   â””â”€â”€ scheduler.py        # Automated scheduling
â”œâ”€â”€ data/                   # Data storage
â”‚   â”œâ”€â”€ raw/                # Raw scraped data
â”‚   â”œâ”€â”€ processed/          # Processed datasets
â”‚   â””â”€â”€ models/             # ML model storage
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example           # Environment template
â””â”€â”€ README.md              # This file
</pre>

# Scrape latest tech stories
scraper = HackerNewsScraper()
stories = scraper.scrape_tech_stories(limit=20)

# Analyze sentiment
analyzer = SentimentAnalyzer()
for story in stories:
    sentiment = analyzer.analyze_text(story['title'])
    print(f"{story['title']}: {sentiment['label']} ({sentiment['score']:.2f})")
Custom Subreddit Monitoring
pythonfrom src.scrapers.reddit_scraper import RedditScraper

scraper = RedditScraper()
custom_subreddits = ['singapore', 'technology', 'startups']
posts = scraper.scrape_custom_list(custom_subreddits, limit_per_sub=50)
Dashboard Integration
The Streamlit dashboard provides:

Real-time metrics: Story counts, sentiment averages, source distribution
Interactive charts: Sentiment trends, popularity over time
Data filtering: By source, time range, sentiment
Live updates: Click "Scrape New Data" for fresh content

# Configuration
Environment Variables
env# API Configuration
NEWS_API_KEY=your_newsapi_key
REDDIT_CLIENT_ID=your_reddit_id
REDDIT_CLIENT_SECRET=your_reddit_secret
REDDIT_USER_AGENT=TrendSense/1.0

# Database
DATABASE_URL=sqlite:///trendsense.db
